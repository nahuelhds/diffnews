{
  "url": "https://www.elobservador.com.uy/nota/inteligencia-artificial-y-el-banco-central-europeo-la-regulacion-de-la-union-europea-20244413350",
  "title": "Inteligencia Artificial y el Banco Central Europeo: la regulación de la Unión Europea",
  "description": "¿Debería la supervisión bancaria quedar exenta de cumplir con la normativa sobre inteligencia artificial? Un análisis sobre las herramientas de supervisión bancaria basadas en inteligencia artificial y la normativa europea. ",
  "links": [
    "https://www.elobservador.com.uy/nota/inteligencia-artificial-y-el-banco-central-europeo-la-regulacion-de-la-union-europea-20244413350",
    "https://www.elobservador.com.uy/nota/inteligencia-artificial-y-el-banco-central-europeo-la-regulacion-de-la-union-europea-20244413350/amp"
  ],
  "image": "https://cdn.elobservador.com.uy/032019/1553276016336.jpg?&cw=600&ch=365",
  "content": "<p><em><strong>Por Daniel Lage Etchart: doctorando en TICs (UDC) Master en Derecho Digital e Inteligencia Artificial (UDC) Master en Banca y Mercados Financieros (UDC) Escribano Público (UDELAR)</strong></em></p><div><p>Las herramientas más comunes de<a href=\"https://www.elobservador.com.uy/nota/-como-la-inteligencia-artificial-esta-cambiando-el-negocio-de-los-bancos-uruguayos--2019322143819\" target=\"_blank\"> supervisión bancaria basadas en Inteligencia Artificial (IA)</a> se pueden clasificar en dos tipos. Las de bajo riesgo, automatizan tareas manuales y permiten un enfoque en tareas de mayor valor. Aunque utilizan modelos de IA explicables, cuando manejan datos personales, deben cumplir con la normativa de protección de datos. A pesar de su clasificación, aún pueden presentar desafíos de ciberseguridad y dependencia tecnológica para los supervisores bancarios. </p><p>El segundo tipo de sistemas de IA utilizados por los supervisores bancarios son los calificados como de alto riesgo. Esta categoría no es uniforme, sino que abarca un amplio espectro de riesgos determinado por una combinación única de factores dentro de cada sistema de IA.</p><p>Estos pueden abarcar una variedad de casos de uso, desde el apoyo en la toma de decisiones humanas hasta la generación de información, y pueden incluir algoritmos que se consideren opacos. Sin embargo, comprender su funcionamiento requiere un conocimiento específico del sistema y un nivel adecuado de explicabilidad para todas las partes interesadas.</p><div><p><img src=\"https://media.cdnp.elobservador.com.uy/032023/1678370754403.webp?&amp;extw=jpg&amp;cw=1024\" /></p><p>Tara Winstead - Pexels</p></div><p>Además de la necesidad de transparencia, las regulaciones deben asegurar el cumplimiento de la buena administración. Esto es especialmente crítico cuando se trata de datos personales, donde se imponen requisitos más estrictos. Las medidas reglamentarias abordan aspectos fundamentales como la transparencia en la finalidad prevista, la gobernanza de datos, los modelos de aprendizaje automático, la supervisión humana y la rendición de cuentas.</p><p>La auditabilidad también juega un papel clave, ya sea por órganos internos o organismos independientes. Antes de su adopción, los supervisores bancarios deben realizar evaluaciones exhaustivas de riesgos e impacto, garantizando que estas aplicaciones de IA de alto riesgo no comprometan la legalidad ni la eficacia de la supervisión bancaria, respetando los derechos fundamentales y los requisitos de buena administración establecidos por la <strong>Unión Europea</strong>. </p><div><h3>Leé también</h3></div><p>Los sistemas de IA que buscan reemplazar o asistir a los supervisores humanos en la toma de decisiones pueden tener implicaciones legales y dificultades para cumplir con los principios de buena administración debido a su naturaleza autónoma y opaca. Una solución propuesta es transformar los modelos de aprendizaje automático opacos en modelos más comprensibles, aunque esto puede implicar un equilibrio entre precisión y practicidad. Es crucial que el<strong> Banco Central Europeo (BCE) </strong>considere el uso exclusivo de IA interpretable para cumplir con los estándares de buena gobernanza, pero también es importante explorar métodos menos interpretables que aún cumplan con los principios de buena administración <em>(1)</em>.</p><div><p><img src=\"https://media.cdnp.elobservador.com.uy/082020/1597767988884/artificial-intelligence-3382507_1920.webp?&amp;extw=jpg&amp;cw=1024\" /></p><p>Pexels</p></div><p>Otra alternativa es investigar métodos explicativos “post-hoc”, que intentan explicar el funcionamiento interno de los sistemas de IA opacos mediante modelos interpretables. Estas técnicas pueden proporcionar una comprensión general del funcionamiento de un sistema de IA o información específica sobre resultados particulares.</p><p>Para abordar estas limitaciones, una tercera opción implica diseñar sistemas de IA explícitos que integren herramientas analíticas para explicar su lógica interna y sus resultados, adaptándose a las necesidades específicas de las partes interesadas en entornos éticos y legales.</p><p>En un contexto más amplio, al igual que la IA utilizada por los sistemas judiciales puede plantear riesgos para los derechos fundamentales al interpretar la ley y aplicarla en situaciones específicas, lo mismo ocurre con el BCE en sus procesos administrativos. Por lo tanto, ante los posibles riesgos para la buena administración, se argumenta que algunas aplicaciones de IA en la supervisión bancaria pueden considerarse de alto riesgo. En estos casos, la legislación de IA regirá el uso de herramientas SupTech por parte del BCE y el Mecanismo Único de Supervisión.</p><div><h3>Leé también</h3></div><p>Dentro de los sistemas de IA se encuentran aquellos prohibidos por la normativa. Se pueden identificar dos escenarios potenciales en relación con el BCE. En primer lugar, existe la posibilidad de implementar un sistema de calificación social para evaluar la solvencia de los bancos, lo cual sería discriminatorio al basarse en métricas no financieras. En segundo lugar, está la utilización de sistemas de IA para llevar a cabo una vigilancia masiva de las actividades financieras, empleando herramientas automatizadas para supervisar de manera amplia y continua las transacciones y operaciones financieras de individuos y entidades, lo que podría infringir la privacidad y los derechos fundamentales de los ciudadanos.</p><div><p><img src=\"https://media.cdnp.elobservador.com.uy/052023/1685362036684.webp?&amp;extw=jpg&amp;cw=1024\" /></p><p>Getty Images</p></div><p>Por otro lado, conviene diferenciar si el BCE actúa como proveedor o usuario de IA de alto riesgo. Como proveedor, al desarrollar internamente sistemas de IA, enfrentaría requisitos más estrictos, mientras que como usuario, al adquirir herramientas de IA en el mercado, estaría sujeto a requisitos menos rigurosos. Sin embargo, el cumplimiento de esta normativa podría afectar la independencia del BCE: como proveedor, podría ser vulnerable a la interferencia de la entidad de la UE encargada de hacer cumplir el Reglamento sobre IA; en cuanto como usuario, su independencia podría verse limitada por los riesgos de depender de proveedores privados de IA, lo que podría violar la doctrina Meroni, que establece que ciertas funciones administrativas delegadas por una institución de la Unión Europea a terceros deben ser ejercidas bajo su supervisión directa.</p><div><h3>Leé también</h3></div><p>Finalmente, y como consecuencia de lo hasta aquí relatado, surge la pregunta: ¿Debería la supervisión bancaria quedar exenta de cumplir con la normativa sobre IA, tal como sucede con los sistemas de IA utilizados en temas de seguridad nacional? Esta interrogante cobra relevancia debido al papel crítico que desempeña la supervisión bancaria en la seguridad económica y social en el ámbito europeo.</p><p><em>(1) Véase, Azzutti, A., et al, Navigating the Legal Landscape of AI-Enhanced Banking Supervision: Protecting EU Fundamental Rights and Ensuring Good Administration, European Banking Institute, 2023- No. 140</em></p></div>",
  "author": "Daniel Lage Etchart",
  "favicon": "https://www.elobservador.com.uy/images/favicons/favicon-16x16.png",
  "source": "elobservador.com.uy",
  "published": "2024-04-04T20:15:18.445Z",
  "ttr": 185,
  "type": "article"
}