{
  "url": "https://www.montevideo.com.uy/Ciencia-y-Tecnologia/El-riesgo-de-alimentar-a-una-inteligencia-artificial-con-datos-generados-por-si-misma-uc896126",
  "title": "El riesgo de alimentar a una inteligencia artificial con datos generados por sí misma",
  "description": "Los modelos de inteligencia artificial (IA) se abastecen sin parar de datos generados por la propia IA, lo que desemboca en la creación de contenidos cada vez más incoherentes, un problema que ya han señalado...",
  "links": [
    "https://www.montevideo.com.uy/Ciencia-y-Tecnologia/El-riesgo-de-alimentar-a-una-inteligencia-artificial-con-datos-generados-por-si-misma-uc896126",
    "https://www.montevideo.com.uy/Ciencia-y-Tecnologia/El-riesgo-de-alimentar-a-una-inteligencia-artificial-con-datos-generados-por-si-misma-uc896126?plantilla=1685&proceso=amp",
    "https://www.montevideo.com.uy/auc.aspx?896126="
  ],
  "image": "https://imagenes.montevideo.com.uy/imgnoticias/202306/_W933_80/848012.jpg",
  "content": "<div>\n                              \t<p>Los modelos de\ninteligencia artificial (IA) se abastecen sin parar de datos generados por la\npropia IA, lo que desemboca en la creación de contenidos cada vez más\nincoherentes, un problema que ya han señalado varios estudios científicos.</p><p>Los modelos en los que\nse basan las herramientas de IA generativa, como ChatGPT, que permiten crear\ntodo tipo de contenidos con simples preguntas, necesitan ser ejercitados con un\nnombre colosal de datos.</p><p>Estos datos a menudo\nvienen de internet, que cada vez contiene más imágenes y textos creados por la\npropia IA.</p><p>Esta autoalimentación\nde la IA lleva a un deterioro de los modelos, que producen respuestas que van\nsiendo cada vez menos originales y pertinentes y acaban por no tener ningún\nsentido, según un artículo publicado a finales de julio por la revista científica\n<em>Nature</em>.</p><p>Con el uso de este tipo\nde datos, llamados “datos sintéticos” porque están generados artificialmente,\nla muestra en la que se basan los modelos de IA para dar respuestas va\nperdiendo calidad.</p><p><strong>Como las vacas locas</strong></p><p>Investigadores de las\nUniversidades de Rice y de Stanford, en Estados Unidos, llegaron a la misma\nconclusión analizando los modelos de IA generadores de imágenes Midjourney,\nDall-E y Stable Diffusion.</p><p>Los estudios mostraron\nque las imágenes generadas eran cada vez menos originales e iban incorporando\nelementos incoherentes a medida que se añadían datos “artificiales” en el\nmodelo, y compararon este fenómeno con la enfermedad de las vacas locas.</p><p>Esta epidemia, surgida\nen el Reino Unido, empezó con el uso para alimentar a los bovinos de harinas\nanimales, obtenidas a partir de partes no consumidas de restos vacunos o de\ncadáveres de animales contaminados.</p><p>Las empresas del sector\nde la IA utilizan a menudo “datos sintéticos” para alimentar a sus programas\ndebido a su fácil acceso, su abundancia y el bajo coste, comparado con datos\ncreados por humanos.</p><p>Estas “fuentes de datos\nhumanos sin explotar, de alta calidad” son cada vez más minoritarias, explica a\n<em>AFP</em> Jathan Sadowski, investigador especializado en las nuevas\ntecnologías de la Universidad de Monash, en Australia.</p><p>“Sin ningún control\ndurante varias generaciones”, la peor hipótesis sería que la degradación de los\nmodelos “envenene la calidad y la diversidad de los datos en todo internet”,\nadvierte Richard Baraniuk, uno de los autores del artículo de la Universidad de\nRice, en un comunicado.</p><p>Así como la crisis de\nlas vacas locas hundió la industria cárnica en los años 1990, un internet\nrepleto de contenidos hechos con IA y de modelos descontrolados podría amenazar\nel futuro del sector, en pleno auge, según los científicos.</p><p>“La verdadera pregunta\npara los investigadores y las empresas que construyen los sistemas de IA es:\n¿cuándo el uso de los datos sintéticos es demasiado?”, dice Sadowski.</p><p><strong>“Basura”</strong></p><p>Para otros\nespecialistas, no obstante, el problema es exagerado.</p><p>Anthropic y Hugging\nFace, dos líderes del sector que afirman tener en cuenta el lado ético de la\ntecnología, confirman a <em>AFP</em> utilizar datos generados por la IA.</p><p>El artículo de la\nrevista Nature presenta una perspectiva teórica interesante, pero poco\nrealista, según Anton Lozhkov, ingeniero en aprendizaje automático en Hugging\nFace.</p><p>“El entrenamiento [de\nlos modelos] en varias series de datos sintéticos es algo que simplemente no se\nhace en realidad”, asegura.</p><p>Lozhkov admite sin\nembargo que los expertos de la IA se sienten frustrados ante la situación en\nque se encuentra internet.</p><p>“Una gran parte de\ninternet es una basura”, dice, y agrega que su empresa ha hecho grandes\nesfuerzos para limpiar este tipo de datos, suprimiendo a veces hasta un 90% de\ncontenido.</p><p><em>AFP / Joseph Boyle</em></p>\n                                </div>",
  "author": "@portalmvd",
  "favicon": "https://www.montevideo.com.uy/favicon/favicon.ico",
  "source": "montevideo.com.uy",
  "published": "",
  "ttr": 115,
  "type": "article"
}