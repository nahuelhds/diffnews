{
  "url": "https://www.montevideo.com.uy/Salud/Estudio-aleman-alerta-por-la-informacion-de-los-chatbots-sobre-medicamentos-uc903234",
  "title": "Estudio alemán alerta por la información de los chatbots sobre medicamentos",
  "description": "Un peligro                                    Fiarse de ellos como fuente puede ser una mala idea, de acuerdo con los resultados de un trabajo llevado a cabo en...",
  "links": [
    "https://www.montevideo.com.uy/Salud/Estudio-aleman-alerta-por-la-informacion-de-los-chatbots-sobre-medicamentos-uc903234",
    "https://www.montevideo.com.uy/Salud/Estudio-aleman-alerta-por-la-informacion-de-los-chatbots-sobre-medicamentos-uc903234?plantilla=1685&proceso=amp",
    "https://www.montevideo.com.uy/auc.aspx?903234="
  ],
  "image": "https://imagenes.montevideo.com.uy/imgnoticias/201809/_W933_80/668338.jpg",
  "content": "<div>\n                            <article>\n                               <div>\n                                    <p>Un peligro</p>\n                                    <h2>Fiarse de ellos como fuente puede ser una mala idea, de acuerdo con los resultados de un trabajo llevado a cabo en Alemania.</h2>\n                                </div> \n                                <div>\n                              \t<p>Los buscadores y chatbots que se basan en la inteligencia\nartificial (IA) no proporcionan información fiable sobre medicamentos, dado que\nlas respuestas son inexactas, advierte un estudio de un instituto alemán de\nfarmacología.</p><p>Wahram Andrikyan, del Instituto de Farmacología y\nToxicología Experimental y Clínica de la Universidad de Erlangen, en el sur de\nAlemania, explicó en el informe publicado en la revista <em>BMJ Quality &amp;\nSafety </em>que las respuestas fueron repetidamente inexactas e incompletas y\na menudo difíciles de entender.</p><p>Por ello, los investigadores aconsejan precaución y reclaman\nque se advierta a los usuarios.</p><p>\"Un hallazgo clave de nuestro estudio es que la calidad\nde las respuestas del chatbot aún no es suficiente para un uso seguro por parte\nde los usuarios\", señaló Andrikyan.</p><p>\"Por lo tanto, en nuestra opinión es esencial que se\nindique claramente que la información proporcionada por el chatbot no puede\nsustituir al asesoramiento profesional\", agregó.</p><p>El punto de partida del estudio fue el hecho de que los\npacientes utilizan internet para informarse sobre la medicación prescrita.</p><p>Por ello, en abril de 2023, los investigadores plantearon al\nchatbot asistido por IA del buscador Bing de Microsoft diez preguntas\nhabituales sobre los 50 medicamentos más recetados en Estados Unidos, incluidas\ncuestiones sobre cómo tomarlos, efectos secundarios y contraindicaciones.</p><p>Andrikyan aclaró que, en general, el chatbot respondió a las\npreguntas con un alto grado de exhaustividad y precisión, pero ese no fue el\ncaso con algunas de las consultas. \"Esto supone un riesgo para los\npacientes, ya que, al no tener conocimientos de medicina, no pueden evaluar por\nsí mismos la precisión y exhaustividad de las respuestas generadas por la\nIA\", comentó el experto.</p><p>El investigador subrayó que se han producido rápidos avances\nen los buscadores asistidos por IA con función de chatbot integrada desde que\nse hizo el estudio el año pasado. Sin embargo, observó que las mejoras no son\nsuficientes y que por el momento persisten los riesgos para la seguridad de los\npacientes.</p><p>Sin embargo, Andrikyan cree que, como los chatbots se\nentrenan con diferentes conjuntos de datos, tiene sentido analizar también la\nseguridad y la calidad de otros sistemas tecnológicos</p><p>DPA</p>\n                                </div> \n                             <br />\n                            </article> \n                            <br />\n                        </div>",
  "author": "@portalmvd",
  "favicon": "https://www.montevideo.com.uy/favicon/favicon.ico",
  "source": "montevideo.com.uy",
  "published": "",
  "ttr": 75,
  "type": "article"
}