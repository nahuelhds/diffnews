{
  "url": "https://www.montevideo.com.uy/Ciencia-y-Tecnologia/OpenAI-dara-acceso-a-sus-modelos-de-lenguaje-al-gobierno-de-EE-UU--uc898598",
  "title": "OpenAI dará acceso a sus modelos de lenguaje al gobierno de EE. UU.",
  "description": "Green light                                    Estos programas permiten generar, según el caso, texto, imágenes o sonido a partir de una instrucción, como el propio...",
  "links": [
    "https://www.montevideo.com.uy/Ciencia-y-Tecnologia/OpenAI-dara-acceso-a-sus-modelos-de-lenguaje-al-gobierno-de-EE-UU--uc898598",
    "https://www.montevideo.com.uy/Ciencia-y-Tecnologia/OpenAI-dara-acceso-a-sus-modelos-de-lenguaje-al-gobierno-de-EE-UU--uc898598?plantilla=1685&proceso=amp",
    "https://www.montevideo.com.uy/auc.aspx?898598="
  ],
  "image": "https://imagenes.montevideo.com.uy/imgnoticias/202407/_W933_80/889211.jpg",
  "content": "<div>\n                            <article>\n                               <div>\n                                    <p>Green light</p>\n                                    <h2>Estos programas permiten generar, según el caso, texto, imágenes o sonido a partir de una instrucción, como el propio ChatGPT.</h2>\n                                </div> \n                                <div>\n                              \t<p>OpenAI, la empresa que lanzó el programa de inteligencia\nartificial (IA) generativa ChatGPT, alcanzó un acuerdo con el gobierno\nestadounidense, al que dará acceso a sus nuevos modelos de lenguaje previo a\nlanzarlos para identificar posibles riesgos.</p><p>Los modelos de lenguaje son programas que permiten generar,\nsegún el caso, texto, imágenes o sonido a partir de una instrucción en lenguaje\ncorriente, como el propio ChatGPT.</p><p>El AI Safety Institute (Instituto de Seguridad para la\nInteligencia Artificial), creado en 2023 por el gobierno de Joe Biden, concluyó\nun acuerdo similar con un competidor de OpenAI, Anthropic, según un comunicado\npublicado el jueves.</p><p>Las dos start-ups se comprometieron a colaborar con el\ninstituto para “evaluar las capacidades (de los modelos) y los riesgos de\nseguridad” que puedan plantear, así como a trabajar en “métodos para gestionar\nestos riesgos”, indicó el organismo.</p><p>“Estos acuerdos son solo un comienzo, pero marcan una etapa\nimportante para ayudar a orientar el futuro de la IA hacia un abordaje\nresponsable”, resumió Elizabeth Kelly, directora del instituto, citada en el\ncomunicado.</p><p>El avance de estos modelos de lenguaje (LLM) aumenta sus\ncapacidades y los riesgos asociados, en particular de uso malintencionado.</p><p>“Una IA segura y confiable es determinante para que esta\ntecnología pueda tener un impacto positivo”, explicó a la <em>AFP</em> Jack\nClark, confundador de Anthropic.</p><p><em>AFP</em></p>\n                                </div> \n                             <br />\n                            </article> \n                            <p>\n                                <strong>Te puede interesar</strong>\n                                <span>\n                                    <a target=\"_blank\" href=\"https://www.montevideo.com.uy/Ciencia-y-Tecnologia/Tecnologia-y-medios-de-comunicacion-de-que-va-el-acuerdo-entre-OpenAI-y-Conde-Nast-uc897727\">Tecnología y medios de comunicación: de qué va el acuerdo entre OpenAI y Condé Nast</a>\n                                </span> \n                            </p> \n                            <br />\n                        </div>",
  "author": "@portalmvd",
  "favicon": "https://www.montevideo.com.uy/favicon/favicon.ico",
  "source": "montevideo.com.uy",
  "published": "",
  "ttr": 51,
  "type": "article"
}