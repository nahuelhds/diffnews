{
  "url": "https://www.elobservador.com.uy/nota/la-inteligencia-artificial-aprende-el-lenguaje-viendo-el-mundo-a-traves-de-los-ojos-de-un-bebe-20242210300",
  "title": "La inteligencia artificial aprende el lenguaje viendo el mundo a través de los ojos de un bebé",
  "description": "Un modelo de inteligencia artificial (IA) aprendió a reconocer palabras como \"cuna\" y \"pelota\" analizando grabaciones tomadas por cámaras frontales durante una pequeña fracción de la vida de un solo bebé. Así...",
  "links": [
    "https://www.elobservador.com.uy/nota/la-inteligencia-artificial-aprende-el-lenguaje-viendo-el-mundo-a-traves-de-los-ojos-de-un-bebe-20242210300",
    "https://www.elobservador.com.uy/nota/la-inteligencia-artificial-aprende-el-lenguaje-viendo-el-mundo-a-traves-de-los-ojos-de-un-bebe-20242210300/amp"
  ],
  "image": "https://cdn.elobservador.com.uy/022024/1706880694347.jpg?&cw=600&ch=365",
  "content": "<p>Un modelo de inteligencia artificial (IA) aprendió a reconocer palabras como \"cuna\" y \"pelota\" analizando grabaciones tomadas por cámaras frontales durante una pequeña fracción de la vida de un solo bebé. Así de simple y sorprendente.</p><div><p>“Los resultados sugieren que la IA puede ayudarnos a comprender cómo aprendemos los humanos”, afirma Wai Keen Vong, coautor del estudio e investigador en IA en la Universidad de Nueva York.</p><p>Los autores esperan que la investigación, publicada en la revista <em>Science</em> alimente debates de larga data sobre cómo los niños aprenden el lenguaje. “No nos dan Internet cuando nacemos. Esta experiencia es única porque otros modelos de aprendizaje de idiomas, como ChatGPT, aprenden con miles de millones de datos, lo que no es comparable a las experiencias del mundo real de un bebé”, dice Vong.</p><p>La IA aprendió creando asociaciones entre las imágenes y las palabras que captó juntas. En otras palabras: el modelo no fue programado con ningún otro conocimiento previo sobre el lenguaje, algo que desafía algunas teorías de las ciencias cognitivas que, para dar significado a las palabras, postulan que los seres humanos necesitamos de algún conocimiento innato.</p><p>“El enfoque del estudio es sencillamente fascinante porque nos permite comprender la adquisición temprana del lenguaje en los niños”, afirma Heather Bortfeld, científica cognitiva de la Universidad de California.</p><p>Vong y sus colegas utilizaron 61 horas de grabaciones de una cámara montada en un casco usado por un bebé llamado Sam, para recopilar las experiencias desde la perspectiva del niño. Sam, que vive cerca de Adelaide, en Australia, usó la cámara durante aproximadamente una hora dos veces por semana desde los seis meses hasta aproximadamente los dos años.</p><p>Los investigadores entrenaron la red neuronal, una IA inspirada en la estructura del cerebro, con los fotogramas del vídeo y las palabras dichas a Sam. El modelo estuvo expuesto a 250.000 palabras y a una cantidad similar de imágenes correspondientes, capturadas durante actividades cotidianas, como jugar, leer y comer.</p><p>El modelo utilizó una técnica llamada “aprendizaje contrastivo” para aprender qué imágenes y textos tienden a ir juntos y cuáles no. De esta forma, el modelo generó información que le permitió predecir a qué imágenes se refieren ciertas palabras, como \"pelota\" y \"taza\".</p><p>Para probar la IA, los investigadores pidieron al modelo que relacionara una palabra con una de cuatro imágenes candidatas, una prueba que también se utiliza para evaluar las habilidades lingüísticas de los niños.</p><p>La IA clasificó con éxito el objeto el 62% de las veces, mucho mejor que el 25% esperado por casualidad, y comparable a un modelo de IA similar que fue entrenado en 400 millones de pares de imágenes y texto fuera de este conjunto de datos.</p><p>Para algunas palabras, como \"manzana\" y \"perro\", el modelo pudo identificar correctamente ejemplos nunca antes vistos, algo que a los humanos generalmente les resulta relativamente fácil. En promedio, lo hizo con éxito el 35% de las veces.</p><p>La IA fue mejor para identificar objetos fuera de contexto cuando aparecían con frecuencia en los datos de entrenamiento. “También fue mejor para identificar objetos que varían poco en su apariencia”, dice Vong. En cambio, las palabras que pueden referirse a una variedad de elementos diferentes, como \"juguete\", le resultaron más difíciles de aprender.</p><p>“La dependencia del estudio de datos de un solo niño podría plantear dudas sobre la generalización de sus hallazgos, porque las experiencias y entornos de los niños varían mucho. Sin embargo, el ejercicio revela que los bebés pueden aprender mucho en sus primeros días de vida simplemente formando asociaciones entre diferentes fuentes sensoriales”, añade Bortfeld.</p><p>Los hallazgos también desafían a los científicos, como al lingüista estadounidense Noam Chomsky, que afirman que el lenguaje es demasiado complejo y la entrada de información es demasiado escasa para que la adquisición del lenguaje se produzca a través de procesos generales de aprendizaje.</p><p>\"Éstos son algunos de los datos más sólidos que he visto que muestran que estos mecanismos 'especiales' no son necesarios\", afirma Bortfeld.</p><p>El aprendizaje de idiomas en el mundo real es mucho más rico y variado que el experimentado por la IA. Los investigadores dicen que, debido a que la IA se limita a entrenar con imágenes fijas y texto escrito, no podría experimentar interacciones inherentes a la vida de un bebé real.</p><p>“De hecho, la IA tuvo dificultades para aprender la palabra ‘mano’, por ejemplo, que normalmente se aprende temprano en la vida de un bebé. Los bebés tienen sus propias manos, tienen mucha experiencia con ellas. Definitivamente es un componente que falta en nuestro modelo”, explica Vong.</p><p>Pese a los hallazgos y el novedoso enfoque, los autores del trabajo señalan que les que queda mucho camino por recorrer para entender cómo adquirimos la capacidad del habla. \"El desafío pasa por seguir perfeccionando el modelo con el objetivo de que esté más alineado con las complejidades del aprendizaje humano. Un desafío enorme, pero que ofrece interesantes vías para avanzar en las ciencias cognitivas\", se entusiasma Anirudh Goyal, científico de aprendizaje automático de la Universidad de Montreal.</p><p><em>(Con información de agencias)</em></p></div>",
  "author": "Redacción",
  "favicon": "https://www.elobservador.com.uy/images/favicons/favicon-16x16.png",
  "source": "elobservador.com.uy",
  "published": "2024-02-02T13:32:33.430Z",
  "ttr": 164,
  "type": "article"
}