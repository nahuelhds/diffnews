{
  "url": "https://www.montevideo.com.uy/Ciencia-y-Tecnologia/Asi-es-el-chip-de-inteligencia-artificial-mas-poderoso-del-mundo-recien-lanzado-por-Nvidia-uc882990",
  "title": "Así es el chip de inteligencia artificial más poderoso del mundo recién lanzado por Nvidia",
  "description": "Superchip                                    Según la compañía, el dispositivo tiene un rendimiento siete veces mayor y ofrece cuatro veces la velocidad de su versión...",
  "links": [
    "https://www.montevideo.com.uy/Ciencia-y-Tecnologia/Asi-es-el-chip-de-inteligencia-artificial-mas-poderoso-del-mundo-recien-lanzado-por-Nvidia-uc882990",
    "https://www.montevideo.com.uy/Ciencia-y-Tecnologia/Asi-es-el-chip-de-inteligencia-artificial-mas-poderoso-del-mundo-recien-lanzado-por-Nvidia-uc882990?plantilla=1685&proceso=amp",
    "https://www.montevideo.com.uy/auc.aspx?882990="
  ],
  "image": "https://imagenes.montevideo.com.uy/imgnoticias/202403/_W933_80/875351.jpg",
  "content": "<div>\n                            <article>\n                               <div>\n                                    <p>Superchip</p>\n                                    <h2>Según la compañía, el dispositivo tiene un rendimiento siete veces mayor y ofrece cuatro veces la velocidad de su versión anterior.</h2>\n                                </div> \n                                <div>\n                              \t<p>El chip H100 de inteligencia artificial de Nvidia la\nconvirtió en una empresa multimillonaria, que puede valer más que Alphabet y\nAmazon, y los competidores han estado luchando por alcanzarla. Pero, según el\nmedio <em>The Verge</em>, tal vez Nvidia esté a punto de ampliar su liderazgo, con la\nnueva GPU Blackwell B200 y el “superchip” GB200.</p><p>Nvidia anunció que la nueva GPU B200 ofrece hasta 20\npetaflops de caballos de fuerza FP4 en sus 208 mil millones de transistores.</p><p>Además, un GB200 que combina dos de esas GPU con una sola\nCPU Grace y puede ofrecer 30 veces más rendimiento para cargas de trabajo de\ninferencia LLM y, al mismo tiempo, ser potencialmente más eficiente.</p><p>“Reduce el costo y el consumo de energía hasta 25 veces” en\ncomparación con un H100, dice Nvidia.</p><p>Para entrenar un modelo de 1,8 billones de parámetros se\nhabrían necesitado anteriormente 8.000 GPU Hopper y 15 megavatios de potencia,\nafirma Nvidia. Hoy, el director ejecutivo de Nvidia dice que 2.000 GPU\nBlackwell pueden hacerlo consumiendo sólo cuatro megavatios.</p><p>En una prueba de referencia GPT-3 LLM con 175 mil millones\nde parámetros, Nvidia dice que el GB200 tiene un rendimiento siete veces mayor que\nun H100, y ofrece cuatro veces la velocidad de entrenamiento.</p><p>Nvidia dijo a los periodistas que una de las claves es un\nmotor transformador de segunda generación que duplica la computación, el ancho\nde banda y el tamaño del modelo mediante el uso de cuatro bits para cada\nneurona, en lugar de ocho (de ahí los 20 petaflops del FP4).</p><p>Una segunda diferencia clave solo surge cuando se conecta\nuna gran cantidad de estas GPU: un conmutador NVLink de próxima generación que\npermite que 576 GPU se comuniquen entre sí, con 1,8 terabytes por segundo de\nancho de banda bidireccional.</p><p>Eso requirió que Nvidia construyera un chip conmutador de\nred completamente nuevo, uno con 50 mil millones de transistores y parte de su\npropia computación integrada: 3,6 teraflops de FP8, dice Nvidia.</p>\n                                </div> \n                             <br />\n                            </article> \n                            <br />\n                        </div>",
  "author": "@portalmvd",
  "favicon": "https://www.montevideo.com.uy/favicon/favicon.ico",
  "source": "montevideo.com.uy",
  "published": "",
  "ttr": 69,
  "type": "article"
}