{
  "url": "https://www.montevideo.com.uy/Ciencia-y-Tecnologia/Entrenan-una-IA-para-aprender-palabras-a-traves-de-la-experiencia-de-un-nino-uc878773",
  "title": "Entrenan una IA para aprender palabras a través de la experiencia de un niño",
  "description": "Estudiar con los mejores                                    Mediante cámaras se recabó alrededor del 1 % de las horas de vigilia de los niños que participaron de la...",
  "links": [
    "https://www.montevideo.com.uy/Ciencia-y-Tecnologia/Entrenan-una-IA-para-aprender-palabras-a-traves-de-la-experiencia-de-un-nino-uc878773",
    "https://www.montevideo.com.uy/Ciencia-y-Tecnologia/Entrenan-una-IA-para-aprender-palabras-a-traves-de-la-experiencia-de-un-nino-uc878773?plantilla=1685&proceso=amp",
    "https://www.montevideo.com.uy/auc.aspx?878773="
  ],
  "image": "https://imagenes.montevideo.com.uy/imgnoticias/202402/_W933_80/870764.jpg",
  "content": "<div>\n                            <article>\n                               <div>\n                                    <p>Estudiar con los mejores</p>\n                                    <h2>Mediante cámaras se recabó alrededor del 1 % de las horas de vigilia de los niños que participaron de la experiencia.</h2>\n                                </div> \n                                <div>\n                              \t<p>Los sistemas de\ninteligencia artificial (IA) aprenden a hablar a partir de enormes cantidades\nde palabras, pero un nuevo estudio ha demostrado que también pueden hacerlo\nusando las grabaciones de lo que ve y oye un bebé durante el primer año y medio\nen que adquiere el lenguaje.</p><p>Un estudio\nencabezado por la Universidad de Nueva York y que publica <em>Science</em>\ndemostró que las herramientas de la IA pueden aprender un número considerable\nde palabras y conceptos a partir de fragmentos limitados de la experiencia del\nniño.</p><p>Los sistemas de\nIA, como ChatGPT-4, aprenden y utilizan el lenguaje humano a partir billones de\ndatos lingüísticos, mientras que los niños solo reciben millones de palabras al\naño cuando aprenden a hablar.</p><p>El equipo decidió\ncomprobar si un modelo de IA podía aprender palabras y conceptos presentes en\nla experiencia cotidiana de un niño solo con la información que recibía este\ndesde los seis meses a los dos años.</p><p>Para ello,\nentrenaron un sistema de IA multimodal a través de los ojos y oídos del\npequeño, usando más de 60 horas de grabación en primera persona, mediante una\ncámara ligera montada en la cabeza.</p><p>La conclusión fue\nque el modelo o red neuronal “podía aprender un número considerable de palabras\ny conceptos a partir de fragmentos limitados de la experiencia del niño”,\nseñaló la Universidad de Nueva York.</p><p>La cámara que\nllevaba el niño solo captaba alrededor del 1 % de sus horas de vigilia, pero\nera suficiente para un auténtico aprendizaje del lenguaje.</p><p>\"Demostramos,\npor primera vez, que una red neuronal entrenada con esta información realista\nsobre el desarrollo de un solo niño puede aprender a relacionar las palabras\ncon sus equivalentes visuales\", destacó el primer autor de las\ninvestigación, Wai Keen Vong.</p><p>Estos resultados,\nsegún el investigador, demuestran cómo los recientes avances algorítmicos\nemparejados con la experiencia naturalista de un solo niño “tienen el potencial\nde remodelar nuestra comprensión de la adquisición temprana del lenguaje y los\nconceptos.\"</p><p>Las grabaciones\ncontenían aproximadamente un cuarto de millón de instancias de palabras, es\ndecir, el número de palabras comunicadas, muchas de ellas repetidas, que están\nvinculadas con fotogramas de vídeo de lo que el niño veía cuando se\npronunciaban.</p><p>Los\ninvestigadores entrenaron una red neuronal multimodal con dos módulos\nseparados: uno que toma fotogramas de vídeo individuales (el codificador de\nvisión) y otro que toma el habla transcrita dirigida por el niño (el\ncodificador de lenguaje). Ambos codificadores se combinaron y entrenaron\nmediante un algoritmo llamado contrastivo, cuyo objetivo es aprender\ncaracterísticas de entrada útiles y sus asociaciones intermodales.</p><p>Por ejemplo,\ncuando uno de los padres dice algo a la vista del niño, es probable que algunas\nde las palabras utilizadas se refieran a una cosa que el pequeño pueda ver, lo\nque significa que la comprensión se inculca vinculando las señales visuales y\nlingüísticas, explicó la Universidad de Nueva York en un comunicado.</p><p>Esto proporciona\nal modelo una pista sobre qué palabras deben asociarse con qué objetos y la\ncombinación de estas pistas es lo que permite al aprendizaje contrastivo\ndeterminar gradualmente qué palabras pertenecen a qué elementos visuales y\ncaptar el aprendizaje de las primeras palabras de un niño.</p><p>Los resultados\nmostraron que el modelo era capaz de aprender un número considerable de\npalabras y conceptos presentes en la experiencia cotidiana del niño.</p><p>Además, podía\ngeneralizar algunas de las palabras aprendidas a instancias visuales muy\ndistintas de las observadas en el entrenamiento, lo que refleja un aspecto que\ntambién se observa en los niños cuando se les somete a pruebas en el\nlaboratorio.</p><p>EFE</p>\n                                </div> \n                             <br />\n                            </article> \n                            <br />\n                        </div>",
  "author": "@portalmvd",
  "favicon": "https://www.montevideo.com.uy/favicon/favicon.ico",
  "source": "montevideo.com.uy",
  "published": "",
  "ttr": 121,
  "type": "article"
}