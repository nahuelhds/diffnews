{
  "url": "https://www.elobservador.com.uy/nota/inteligencia-artificial-y-seguridad-social-el-caso-syri-202411585919",
  "title": "Inteligencia Artificial y Seguridad Social: el caso SyRI",
  "description": "En los Países Bajos, el Sistema de Indicación de Riesgos (en neerlandés, “Systeem Risico Indicatie” -SyRI-) generó controversia como instrumento, con base legal, utilizado por el gobierno para prevenir y...",
  "links": [
    "https://www.elobservador.com.uy/nota/inteligencia-artificial-y-seguridad-social-el-caso-syri-202411585919",
    "https://www.elobservador.com.uy/nota/inteligencia-artificial-y-seguridad-social-el-caso-syri-202411585919/amp"
  ],
  "image": "https://cdn.elobservador.com.uy/032019/1553275936355.jpg?&cw=600&ch=365",
  "content": "<p>En los Países Bajos, el Sistema de Indicación de Riesgos (en neerlandés, “Systeem Risico Indicatie” -SyRI-) generó controversia como instrumento, con base legal, utilizado por el gobierno para prevenir y combatir el fraude en áreas como la Seguridad Social, los impuestos y las leyes laborales. En su momento, se estimó un fraude a la Seguridad Social de 153 millones de euros. SyRI se desplegó en áreas catalogadas como \"barrios problemáticos\", caracterizadas por elevadas tasas de pobreza, delincuencia y de personas beneficiarias de asistencia social.</p><div><p>El barrio Afrikaander en Rotterdam fue pionero en la implementación de SyRI en los Países Bajos, caracterizándose por tener una población mayoritaria de origen extranjero, principalmente de Turquía y Marruecos. Este sistema de Inteligencia Artificial (IA) vincula y analiza datos de manera anónima en un entorno seguro, generando informes de riesgo.</p><p>Este informe implica que una persona jurídica o física se considera digna de ser investigada por posibles fraudes, uso ilícito e incumplimiento de la ley. SyRI es utilizado a solicitud de diversos organismos estatales, tales como Autoridades Municipales, la Administración Tributaria y Aduanera, el Servicio de Inmigración y Naturalización, así como Autoridades de Supervisión SyRI reúne una amplia gama de datos, desde información laboral y fiscal hasta detalles sobre bienes y motivos de exclusión de beneficios sociales.</p><p>Entre los datos recopilados se encuentran los de identificación, tanto para personas físicas como jurídicas, abarcando nombres, género, direcciones postales. Además, el sistema incluye datos sobre integración cívica, cumplimiento legal, historial educativo, derechos de pensiones y devoluciones de prestaciones. También se registran datos financieros, como deudas, beneficios sociales, subsidios y subvenciones.</p><p>Los permisos y exenciones, así como la información sobre seguros de atención médica, completan este extenso conjunto de datos utilizado por SyRI. La variedad de categorías de datos disponibles es extensa y se detalla de manera exhaustiva. Además, la cantidad de datos utilizables en la implementación de SyRI es significativa, compuesta por un total de 17 categorías de datos de diversos tipos.</p><p>Cada categoría, por sí sola, abarca una cantidad considerable de información. La magnitud de conjuntos de datos estructurados provenientes de diversas fuentes puede variar dependiendo del proyecto específico de SyRI. El Estado argumentó, en sede judicial, que SyRI no es una aplicación de aprendizaje profundo ni un sistema autónomo. Su función no es predecir infracciones, sino comparar archivos de datos existentes de entidades gubernamentales para identificar discrepancias. Si se detecta un desfase, se examina antes de tomar decisión alguna, involucrando a múltiples partes designadas por la ley que estableció el uso de SyRI. Sin embargo, el Tribunal no pudo valorar lo aseverado por el Estado sobre la naturaleza de SyRI, ya que este no reveló el modelo de riesgo ni los indicadores utilizados.</p><p>El Estado no proporcionó información verificable que permitiera al Tribunal evaluar el sistema, alegando que la divulgación podría llevar a “ajustes” en el comportamiento ciudadano. La legislación en la que se apoya SyRI, tampoco explica cómo funciona el modelo de decisión ni qué indicadores se utilizan en los diversos proyectos. Aunque el Tribunal sostuvo que el uso de SyRI en sí mismo no tiene como objetivo procurar consecuencias legales, ya sea en el ámbito del derecho privado, administrativo o penal, un informe de riesgos sí tiene un efecto significativo similar en la vida privada de la persona a la que se refiere.</p><p>El hecho de que un informe de riesgos no siempre conduzca a investigaciones o sanciones, y no se emplee como la única base para la toma de decisiones, su efecto significativo en la vida privada del interesado no se ve disminuido. Los avances tecnológicos posibilitan que los organismos públicos analicen grandes volúmenes de datos a través de sistemas de IA, mejorando así la supervisión. Sin embargo, esta recopilación y análisis de datos pueden tener un impacto significativo en la privacidad de las personas. Por lo tanto, es crucial que la legislación que respalde esta intervención incluya garantías adecuadas para prevenir abusos y arbitrariedades. La falta de transparencia de este sistema dificulta la verificación del proceso de toma de decisiones detrás del informe de riesgos y los pasos específicos involucrados. En consecuencia, se vuelve complejo para un individuo, cuyos datos se han procesado en SyRI, defenderse si se presenta un informe de riesgo en su contra.</p><p>La Alta Corte de los Países Bajos sentenció que SyRI violaba el derecho a la privacidad, indicando que recopilaba datos de manera indiscriminada y sin una base legal clara. Por lo tanto, declaró inaplicables varios artículos claves de la legislación que autorizaba el uso de SyRI. No obstante, según el informe de Riesgo Algorítmico de la Autoridad Holandesa de Protección de Datos de julio de 2023, se destaca que las autoridades municipales continúan utilizando algoritmos opacos para anticipar posibles riesgos de fraude. El gobierno holandés ha comunicado su intención de establecer un \"registro de algoritmos\" obligatorio para que los organismos públicos informen los sistemas algorítmicos que emplean. Además, se les exigirá realizar evaluaciones de impacto en los derechos humanos antes de la implementación de dichos sistemas.</p><p>El próximo Reglamento de Inteligencia Artificial de la Unión Europea categoriza sistemas como SyRI como de alto riesgo, estableciendo exigencias que incluyen la gestión de riesgos, gobernanza de datos, transparencia y supervisión humana. Además, se requieren evaluaciones de conformidad y se habilita el acceso al código fuente, sujeto a requisitos especiales y obligaciones de confidencialidad</p></div>",
  "author": "Daniel Lage Etchart",
  "favicon": "https://www.elobservador.com.uy/images/favicons/favicon-16x16.png",
  "source": "elobservador.com.uy",
  "published": "2024-01-15T11:59:28.885Z",
  "ttr": 176,
  "type": "article"
}