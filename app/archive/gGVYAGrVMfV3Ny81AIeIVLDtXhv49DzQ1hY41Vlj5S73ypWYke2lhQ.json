{
  "url": "https://www.elobservador.com.uy/nota/el-reloj-del-juicio-final-a-solo-90-segundos-de-la-medianoche-de-la-catastrofe-global--20241249270/amp",
  "title": "El Reloj del Juicio Final a sólo 90 segundos de la medianoche de la catástrofe global ",
  "description": "Si bien la posición de la aguja del reloj se mantiene igual a la del año pasado, la permanencia de múltiples amenazas globales indica que la humanidad sigue enfrentándose a un peligro sin precedentes",
  "links": [
    "https://www.elobservador.com.uy/nota/el-reloj-del-juicio-final-a-solo-90-segundos-de-la-medianoche-de-la-catastrofe-global--20241249270",
    "https://www.elobservador.com.uy/nota/el-reloj-del-juicio-final-a-solo-90-segundos-de-la-medianoche-de-la-catastrofe-global--20241249270/amp"
  ],
  "image": "https://cdn.elobservador.com.uy/012024/1706099301197.jpg?&cw=600&ch=365",
  "content": "<p>Tendencias ominosas continúan apuntando al mundo hacia una catástrofe global. La guerra en Ucrania y la presencia generalizada y creciente de las armas nucleares aumentan el riesgo de una escalada nuclear. China, Rusia y Estados Unidos están gastando enormes sumas de dinero para ampliar o modernizar sus arsenales nucleares, lo que aumenta el peligro siempre presente de una guerra nuclear por accidente o error de cálculo.</p><div><p>En 2023, la Tierra experimentó el año más caluroso jamás registrado y enormes inundaciones, incendios forestales y otros desastres relacionados con el clima afectaron a millones de personas en todo el mundo. Mientras tanto, se aceleraron los rápidos y preocupantes avances en las ciencias biológicas y otras tecnologías disruptivas, mientras que los gobiernos sólo hicieron débiles esfuerzos para controlarlos.</p><p>Los miembros de la Junta de Ciencia y Seguridad estuvieron profundamente preocupados por el deterioro del estado del mundo. Es por eso que fijaron el Reloj del Juicio Final a dos minutos para la medianoche en 2019 y a 100 segundos para la medianoche en 2022. El año pasado, se movió el Reloj a 90 segundos para la medianoche, lo más cercano a una catástrofe global que jamás haya existido. Esto se debe en gran parte a las amenazas rusas de utilizar armas nucleares en la guerra de Ucrania.</p><p>Fundado en 1945 por Albert Einstein, J. Robert Oppenheimer y científicos de la Universidad de Chicago que ayudaron a desarrollar las primeras armas atómicas en el Proyecto Manhattan, el Boletín de Científicos Atómicos creó el “Reloj del Juicio Final” dos años más tarde, utilizando imágenes del apocalipsis (medianoche) y el lenguaje contemporáneo de explosión nuclear (cuenta regresiva hasta cero) para graficar las amenazas a la humanidad y al planeta. El Reloj del Juicio Final lo fija cada año la Junta de Ciencia y Seguridad del Boletín en consulta con su Junta de Patrocinadores, que incluye a nueve premios Nobel. El Reloj se convirtió en un indicador universalmente reconocido de la vulnerabilidad del mundo a una catástrofe global causada por tecnologías creadas por el hombre.</p><p>Hoy, el reloj sigue fijo a los 90 segundos para la medianoche porque la humanidad continúa enfrentándose a un nivel de peligro sin precedentes. Según la Junta, la decisión no debe tomarse como una señal de que la situación de seguridad internacional mejoró. En cambio, los líderes y ciudadanos de todo el mundo deberían tomar esta declaración como una cruda advertencia y responder con urgencia, como si hoy fuera el momento más peligroso de la historia moderna porque bien puede serlo.</p><p><strong>La amenaza nuclear</strong></p><p>Según la Junta, parece lejano un fin duradero de la guerra de Rusia en Ucrania, y el uso de armas nucleares por parte de Rusia en ese conflicto sigue siendo una posibilidad seria. En febrero de 2023, el presidente ruso Vladimir Putin anunció su decisión de “suspender” el Nuevo Tratado de Reducción de Armas Estratégicas (Nuevo START). En marzo anunció el despliegue de armas nucleares tácticas en Bielorrusia.</p><p>En junio, Sergei Karaganov, asesor de Putin, instó a Moscú a considerar el lanzamiento de ataques nucleares limitados en Europa occidental como forma de llevar la guerra en Ucrania a una conclusión favorable. En octubre, la Duma rusa votó a favor de retirar la ratificación por parte de Moscú del Tratado de Prohibición Completa de los Ensayos Nucleares, mientras el Senado de Estados Unidos seguía negándose incluso a debatir la ratificación.</p><p>Los programas de gasto nuclear en las tres mayores potencias nucleares –China, Rusia y Estados Unidos– amenazan con desencadenar una carrera armamentista nuclear a tres bandas a medida que la arquitectura de control de armamentos del mundo colapsa. Rusia y China están ampliando sus capacidades nucleares y aumenta la presión en Washington para que Estados Unidos responda de la misma manera.</p><p>Mientras tanto, otras posibles crisis nucleares se agravan. Irán continúa enriqueciendo uranio hasta alcanzar un grado cercano al de armas, mientras obstaculiza a la Agencia Internacional de Energía Atómica en cuestiones clave. Parece poco probable que los esfuerzos para restablecer un acuerdo nuclear con Irán tengan éxito, y Corea del Norte continúa construyendo armas nucleares y misiles de largo alcance. La expansión nuclear en Pakistán y la India continúa sin pausa ni restricciones.</p><p>Y la guerra en Gaza entre Israel y Hamas tiene el potencial de escalar hasta convertirse en un conflicto más amplio en Medio Oriente que podría plantear amenazas impredecibles, a nivel regional y global.</p><div><p><img src=\"https://media.cdnp.elobservador.com.uy/012024/1706099402245/APERTURA%20El%20reloj%20del%20juicio%20final%20Foto%202.webp?&amp;extw=jpg&amp;cw=1024\" /></p><p>Wallpaper Flare</p></div><p><strong>El cambio climático</strong></p><p>La Junta de Ciencia y Seguridad señala que, en 2023, el mundo entró en territorio inexplorado, ya que sufrió el año más caluroso registrado y las emisiones globales de gases de efecto invernadero continuaron aumentando. Las temperaturas de la superficie del mar tanto a nivel mundial como en el Atlántico norte batieron récords, y el hielo marino de la Antártida alcanzó su extensión diaria más baja desde la llegada de los datos satelitales.</p><p>El mundo ya corre el riesgo de superar el objetivo del acuerdo climático de París (un aumento de la temperatura de no más de 1,5°C por encima de los niveles preindustriales) debido a compromisos insuficientes para reducir las emisiones de gases de efecto invernadero y a la implementación insuficiente de los compromisos ya asumidos. Para detener un mayor calentamiento, el mundo debe alcanzar cero emisiones netas de dióxido de carbono.</p><p>El mundo invirtió una cifra récord de US$ 1,7 billones en energía limpia en 2023, y los países que representan la mitad del Producto Bruto Interno mundial se comprometieron a triplicar su capacidad de energía renovable para 2030. Sin embargo, para compensar esto hubo inversiones en combustibles fósiles de casi US$ 1 billón.</p><p>En resumen, los esfuerzos actuales para reducir las emisiones de gases de efecto invernadero son tremendamente insuficientes para evitar los peligrosos impactos humanos y económicos del cambio climático, que afectan desproporcionadamente a las personas más pobres del mundo. A menos que se realice un marcado aumento de los esfuerzos, el costo del sufrimiento humano causado por la alteración del clima aumentará inexorablemente.</p><p><strong>Amenazas biológicas</strong></p><p>Para la Junta, la revolución en las ciencias biológicas y las tecnologías asociadas siguieron ampliando su alcance el año pasado, incluyendo, especialmente, la mayor sofisticación y eficiencia de las tecnologías de ingeniería genética. Se destaca un tema de especial preocupación: la convergencia de herramientas emergentes de Inteligencia Artificial (IA) y tecnologías biológicas puede empoderar radicalmente a los individuos para hacer un mal uso de la biología.</p><p>En octubre, el presidente de Estados Unidos, Joe Biden, firmó una orden ejecutiva sobre “IA segura y confiable” que exige protección “contra los riesgos de usar IA para diseñar materiales biológicos peligrosos mediante el desarrollo de nuevos estándares sólidos para la detección de síntesis biológica”. Aunque es una medida útil, la orden no es jurídicamente vinculante.</p><p>La preocupación –indican los científicos de la Junta– es que los grandes modelos de lenguaje permitan a individuos que de otro modo carecerían de conocimientos suficientes identificar, adquirir y desplegar agentes biológicos que dañarían a un gran número de humanos, animales, plantas y otros elementos del medio ambiente. Los esfuerzos revitalizados el año pasado en Estados Unidos para revisar y fortalecer la supervisión de las investigaciones riesgosas en ciencias biológicas son útiles, pero se necesita mucho más.</p><p><strong>Los peligros de la IA</strong></p><p>Uno de los avances tecnológicos más significativos del último año implicó el espectacular avance de la IA generativa. La aparente sofisticación de los chatbots basados en grandes modelos de lenguaje, como ChatGPT, llevó a algunos expertos a expresar preocupación por los riesgos existenciales que surgen de nuevos avances rápidos en este campo.</p><p>Pero otros argumentan que las afirmaciones sobre el riesgo existencial distraen de las amenazas reales e inmediatas que plantea la IA en la actualidad. De todos modos, la IA es una tecnología disruptiva paradigmática; Se deben ampliar los esfuerzos recientes para la gobernanza global de la IA.</p><p>La IA tiene un gran potencial para magnificar la desinformación y corromper el entorno informativo del que depende la democracia. Los esfuerzos de desinformación basados en la IA podrían ser un factor que impida que el mundo afronte eficazmente los riesgos nucleares, las pandemias y el cambio climático.</p><p>Los usos militares de la IA se están acelerando. Ya se está utilizando ampliamente la IA en inteligencia, vigilancia, reconocimiento, simulación y capacitación. De particular preocupación son las armas letales autónomas, que identifican y destruyen objetivos sin intervención humana. Las decisiones de poner a la IA en control de importantes sistemas físicos (en particular, las armas nucleares) podrían de hecho representar una amenaza existencial directa para la humanidad.</p><p>Afortunadamente, muchos países están reconociendo la importancia de regular la IA y están comenzando a tomar medidas para reducir el potencial de daño. Estos pasos iniciales incluyen una propuesta de marco regulatorio por parte de la Unión Europea, una orden ejecutiva del presidente Biden, una declaración internacional para abordar los riesgos de la IA y la formación de un nuevo órgano asesor de la ONU. Pero estos son sólo pequeños pasos; se debe hacer mucho más para instituir reglas y normas efectivas, a pesar de los enormes desafíos que implica gobernar la inteligencia artificial.</p><p><strong>Para retroceder el reloj</strong></p><p>La junta de científicos señala que todos en la Tierra tienen interés en reducir la probabilidad de una catástrofe global causada por las armas nucleares, el cambio climático, los avances en las ciencias biológicas, las tecnologías disruptivas y la corrupción generalizada del ecosistema de información mundial. Estas amenazas, singularmente y a medida que interactúan, son de tal carácter y magnitud que ninguna nación o líder puede controlarlas.</p><p>Ésa sería la tarea de los líderes y las naciones que trabajan juntos en la creencia compartida de que las amenazas comunes exigen una acción común. Como primer paso, y a pesar de sus profundos desacuerdos, tres de las principales potencias del mundo (Estados Unidos, China y Rusia) deberían iniciar un diálogo serio sobre cada una de las amenazas globales.</p><p>En los niveles más altos, estos tres países deben asumir la responsabilidad del peligro existencial que enfrenta el mundo ahora. Tienen la capacidad de sacar al mundo del borde de la catástrofe. Deben hacerlo con claridad y valentía y sin demora.</p><p>Faltan sólo 90 segundos para la medianoche.</p></div>",
  "author": "Redacción",
  "favicon": "https://www.elobservador.com.uy/images/favicons/favicon-16x16.png",
  "source": "elobservador.com.uy",
  "published": "2024-01-24T12:31:11.159Z",
  "ttr": 331,
  "type": "article"
}