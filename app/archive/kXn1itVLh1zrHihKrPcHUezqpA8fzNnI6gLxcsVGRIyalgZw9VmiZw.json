{
  "url": "https://www.elpais.com.uy/opinion/columnistas/densa-niebla",
  "title": "Densa niebla",
  "description": "Uno de los filósofos de la tecnología más importantes fue Albert Borgmann (1937-2023), quien en sus trabajos describió algo que todos sentimos pero que es difícil conceptualizar. Básicamente, Borgmann sostuvo...",
  "links": [
    "https://www.elpais.com.uy/opinion/columnistas/densa-niebla"
  ],
  "image": "https://imgs.elpais.com.uy/dims4/default/6bfc0ab/2147483647/strip/true/crop/1440x700+0+0/resize/1440x700!/quality/90/?url=https%3A%2F%2Fel-pais-uruguay-production-web.s3.us-east-1.amazonaws.com%2Fbrightspot%2Fc5%2Ff9%2F5af15c6a49008f02d397c5e0d189%2Fdescarga.jpeg",
  "content": "<div>\n<p>Uno de los filósofos de la tecnología más importantes fue Albert Borgmann (1937-2023), quien en sus trabajos describió algo que todos sentimos pero que es difícil conceptualizar. Básicamente, Borgmann sostuvo que en muchos ámbitos de la vida social los rendimientos marginales de más tecnología resultan decrecientes, y que la comodidad y la seguridad no necesariamente conducen a una buena vida. Es pensar si vivir en una sociedad como la de Un Mundo Feliz vale la pena.</p><p>El efecto de Internet ha sido tan profundo que es difícil recordar o imaginar el mundo antes, o sin, esta tecnología, a menos que se supere cierta edad. Borgmann propuso en algunos escritos la metáfora de que las tecnologías de la información (desde leer las nubes, la escritura, hasta Internet), van configurando una niebla que históricamente ha ido aumentando en espesor. En nuestra época, es muy espesa, y por lo tanto nos desorienta particularmente. El problema no es que no podamos encontrar lo que buscamos, sino que no estamos seguros de qué buscar en primer lugar. Cuando todo está disponible, todo se nivela; nada está verdaderamente presente en la medida que se transforma en una posibilidad entre otras, y nos volvemos incapaces de reconocer los valores objetivos de la realidad y por lo tanto de juzgarla. Borgmann sugiere que esto tiene un efecto en la cultura y las personas que no es evidente ni espectacular, sino que es sutil y furtivo.</p><p>La Inteligencia Artificial (IA) o el Internet de las cosas, en sus aplicaciones reales, pero también en los delirios de algunos tecnólogos, confunden y hacen aún más espesa a la niebla. El problema es que se llega al punto en que lo que somos como seres humanos se cuestiona. El CEO de OpenAI, Sam Altman ha señalado nuestra situación poshumana, porque hace tiempo nuestros teléfonos nos controlan y nos dicen qué hacer, las redes sociales nos determinan nuestros sentimientos, y los motores de búsqueda nos dicen qué pensar. A principios de junio, en la conferencia mundial de desarrolladores de Apple, se mostró que se va a incluir IA en los IPhones para que resuma emails o mensajes de grupos, que mande mensajes por el usuario, etc., y va a incluir hasta una función en la que las fotos que sacamos sean arregladas con una narración diseñada por la IA. El teléfono nos va a ir reemplazando y definir hasta cómo recordamos. Los criterios humanistas de racionalidad y autonomía que hemos utilizado desde la ilustración para describirnos se han vuelto inadecuados.</p><p>Con la afirmación “nunca hemos sido modernos”, el sociólogo Bruno Latour se refirió a que ha sido un error histórico el establecer una división profunda entre lo humano y lo que no lo es. Esta es una forma iluminadora de entendernos, pero estamos llegando a un punto de desorientación tan interesante donde inclusive se ve a tecnología como la IA con asombro divino, como algo trascendente y como sustituto para nuestro pensamiento. El ingeniero informático y crítico Jaron Lanier ha escrito que, si bien la IA no es inteligente (sino que es solo una serie de algoritmos y códigos que recopilan toda la información que ponemos en internet y luego usa tablas estadísticas para descubrir correlaciones y predecir respuestas a preguntas) se le ve de forma religiosa. Esto se debe a que existe tanto la esperanza de que la IA redima al mundo de la estupidez humana así como que existe el temor de que nos destruya. En un plano más mundano, en su libro reciente, The AI Mirror, la filósofa Shannon Vallor se pregunta qué significa para la humanidad la tendencia de delegar a máquinas la capacidad de pensar y hasta de tomar decisiones morales. Para esta autora, lo que está pasando es el reemplazo del discernimiento reflexivo por la predicción sin pensamiento en el que no hay espacio para la personalidad humana, la que fundamentalmente se mueve en el espacio de justificaciones morales. Lo que los seres humanos hacemos es tomar decisiones de las que luego podemos hacernos responsables, pero los sistemas técnicos nos transforman en variables discretas y calculables, sin contexto ni razones, para predecirnos y que seamos como máquinas.</p><p>Lo bueno de la IA y los datos, se dice, es que pueden ser más objetivos y razonables, ya que no involucran emociones. Pero la pregunta es si las capacidades de calcular y predecir son las que nos hacen propiamente humanos. ¿Son la eficiencia o lo óptimo los valores humanos supremos y los que nos hacen inteligentes? ¿Es adecuado vernos como computadoras, pero limitadas e ineficientes? Por ejemplo, cuando se probó un coche autónomo en San Francisco, este se quedó trancado en una intersección porque no entendía la situación. Cuando uno maneja, hay una coordinación de miradas y gestos entre personas para ver quién avanza. El sistema de IA es incapaz de entender esos matices humanos. Al analizar la situación, el ingeniero de Google llegó a la conclusión que las personas tienen que ser “menos idiotas”, es decir, que tienen que portarse más como computadoras. Esto es también lo que pasa con el VAR en el fútbol, donde se dan situaciones ridículas en las que se anulan goles porque la computadora dice que un jugador tiene la punta del zapato adelantada.</p><p>Autores como Jacques Ellul o Ivan Illich señalaron tempranamente la tendencia que los humanos no somos liberados por las máquinas, sino que terminamos trabajando para ellas en la medida que la eficiencia se vuelve el valor supremo. Algo se determina como bueno si se hizo rápida y fácilmente, y el progreso humano se vuelve equivalente al progreso tecnológico. La tecnología se vuelve un fin en sí mismo, y por eso es que la educación en STEM y programar son las más fundamentales y promovidas en sociedades tecnológicas, mientras que las humanidades pierden valor. Si seguimos identificando el progreso con la eficiencia y tecnología como la desarrollan algunos en Silicon Valley ahora, vamos muertos. Hay consenso en que la niebla es demasiado espesa y no nos permite ver nada. Si seguimos, quizá nos caigamos por un barranco.</p><p><i>* Doctor en Sociología por la Universidad de Carleton (Canadá) y Director Académico de la Licenciatura en Política, Filosofía y Economía de la Universidad de Montevideo.</i><br /></p>\n</div>",
  "author": "https://www.elpais.com.uy/autor/alexander-castleton",
  "favicon": "https://www.elpais.com.uy/favicon-16x16.png",
  "source": "elpais.com.uy",
  "published": "2024-07-06T05:45:00.598",
  "ttr": 206,
  "type": "article"
}