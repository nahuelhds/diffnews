{
  "url": "https://www.elobservador.com.uy/nota/la-organizacion-mundial-de-la-salud-advirtio-sobre-los-peligros-de-la-inteligencia-artificial-202411811539",
  "title": "La Organización Mundial de la Salud advirtió sobre los peligros de la Inteligencia Artificial",
  "description": "La Organización Mundial de la Salud (OMS) instó a los investigadores a prestar mayor atención a los resultados derivados mediante uso de la inteligencia artificial ante la posibilidad que provoque resultados...",
  "links": [
    "https://www.elobservador.com.uy/nota/la-organizacion-mundial-de-la-salud-advirtio-sobre-los-peligros-de-la-inteligencia-artificial-202411811539",
    "https://www.elobservador.com.uy/nota/la-organizacion-mundial-de-la-salud-advirtio-sobre-los-peligros-de-la-inteligencia-artificial-202411811539/amp"
  ],
  "image": "https://cdn.elobservador.com.uy/012024/1705589494998.jpg?&cw=600&ch=365",
  "content": "<p>La Organización Mundial de la Salud (OMS) instó a los investigadores a prestar mayor atención a los resultados derivados mediante uso de la inteligencia artificial ante la posibilidad que provoque resultados falsos, inexactos, sesgados o incompletos.</p><div><p>El documento elaborado por el organismo de Naciones Unidas (ONU) admite, sin embargo, que la IA generativa podría revolucionar la atención a la salud facilitando, por ejemplo, el desarrollo de fármacos o acelerando la detección de enfermedades.</p><p>El informe evalúa los peligros y ventajas del uso de grandes modelos multimodales (LMM), un tipo de tecnología de IA generativa de rápido crecimiento en materia de salud que utiliza varios tipos de datos, incluidos texto, imágenes y videos.</p><p>Los expertos de la OMS señalan que los resultados no se limitan a los datos introducidos en el algoritmo y que “a medida que se utilizan cada vez más los LMM en la asistencia sanitaria y la medicina, los errores y el mal uso pueden causar perjuicios irreparables a las personas”.</p><p>La organización define cinco áreas que podrían utilizar esta tecnología: el cribado, para responder por ejemplo a peticiones escritas de los pacientes; la investigación científica y el desarrollo de fármacos; la educación médica y de enfermería; las tareas administrativas; y el uso por parte de los pacientes, por ejemplo para analizar síntomas.</p><p>El documento también presenta nuevas directrices sobre la ética y la gestión de los LMM, con más de 40 recomendaciones para los gobiernos, las empresas tecnológicas y los proveedores de atención sanitaria sobre cómo beneficiarse de esta tecnología de forma segura.</p><p>\"Las tecnologías de IA generativa tienen el potencial de mejorar los cuidados de salud, pero sólo si aquellos que desarrollan, regulan y utilizan estas tecnologías identifican y tienen plenamente en cuenta los riesgos asociados\", afirmó el científico jefe de la OMS, Jeremy Farrar.</p><p>El documento, además, pide a los reguladores nacionales que establezcan normas de responsabilidad para \"garantizar que los usuarios perjudicados por un LMM sean indemnizados adecuadamente o dispongan de otras formas de recurso\".</p><p>La OMS también subraya que existen dudas sobre el cumplimiento de la normativa vigente por parte de los LMM, especialmente en materia de protección de datos, lo que podría derivar en la estigmatización de los pacientes.</p><p>La agencia de la ONU señala también el hecho de que los LMM son a menudo desarrollados e implantados por gigantes tecnológicos, por lo que recomienda que los profesionales de la salud y pacientes también participen en el proceso.</p><p>Por último, el documento concluye que los gobiernos deberían encargar a las autoridades reguladoras que aprueben el uso de los LMM en la atención sanitaria, al tiempo que pide que se realicen auditorías para evaluar el impacto de la tecnología.</p><p><em>(Con información de AFP)</em></p></div>",
  "author": "Redacción",
  "favicon": "https://www.elobservador.com.uy/images/favicons/favicon-16x16.png",
  "source": "elobservador.com.uy",
  "published": "2024-01-18T14:53:09.216Z",
  "ttr": 88,
  "type": "article"
}